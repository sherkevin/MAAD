# 服务器优化配置
# 针对Linux GPU服务器环境优化

server:
  platform: "linux"
  gpu_enabled: true
  cuda_version: "11.8"
  pytorch_version: "2.8.0"
  memory_limit_gb: 64
  batch_size: 64
  num_workers: 8

# 多智能体配置
multi_agent:
  num_agents: 5
  communication_rounds: 10
  fusion_method: "weighted_average"
  confidence_threshold: 0.7
  
  agents:
    trend_agent:
      type: "TrendAgent"
      threshold: 0.6
      window_size: 10
      smoothing_factor: 0.1
      
    seasonal_agent:
      type: "SeasonalAgent"
      period: 24
      threshold: 0.7
      seasonal_weight: 0.8
      
    residual_agent:
      type: "ResidualAgent"
      threshold: 0.5
      noise_level: 0.1
      
    coordinator_agent:
      type: "CoordinatorAgent"
      decision_threshold: 0.6
      consensus_required: 0.8

# 通信配置
communication:
  protocol: "T2MAC"
  llm_model: "Qwen-7B-Chat"
  strategy: "dynamic_adaptive"
  max_rounds: 5
  timeout_seconds: 30
  
  t2mac:
    adaptation_rate: 0.1
    communication_threshold: 0.7
    efficiency_weight: 0.8

# 隐私保护配置
privacy:
  enabled: true
  mechanism: "differential_privacy"
  epsilon: 1.0
  delta: 1e-5
  sensitivity: 1.0
  
  budget_management:
    total_epsilon: 10.0
    total_delta: 1e-4
    per_query_epsilon: 0.1
    per_query_delta: 1e-6

# 联邦学习配置
federated_learning:
  enabled: true
  num_clients: 10
  num_rounds: 50
  local_epochs: 10
  learning_rate: 0.01
  aggregation_method: "fedavg"
  client_selection_ratio: 0.8
  
  privacy:
    enabled: true
    epsilon: 2.0
    delta: 1e-5
    mechanism: "gaussian"
    sensitivity: 1.0

# 实验配置
experiments:
  # 多智能体实验
  multi_agent:
    num_samples: 10000
    batch_size: 64
    data_shapes: [[1, 3, 64, 64], [1, 3, 128, 128], [1, 3, 256, 256]]
    target_throughput: 2000  # 样本/秒
    
  # 通信实验
  communication:
    num_rounds: 1000
    agent_scenarios: 10
    target_latency: 0.05  # 秒
    
  # 隐私实验
  privacy:
    num_operations: 5000
    data_size: 200
    test_mechanisms: ["laplace", "gaussian", "exponential"]
    
  # 联邦学习实验
  federated:
    num_clients: 10
    num_rounds: 50
    local_epochs: 10
    samples_per_client: 1000

# 性能监控
monitoring:
  enable_profiling: true
  profile_interval: 10
  log_level: "INFO"
  save_checkpoints: true
  checkpoint_interval: 100
  
  metrics:
    - "throughput"
    - "latency"
    - "memory_usage"
    - "gpu_utilization"
    - "accuracy"
    - "privacy_budget"

# 输出配置
output:
  save_results: true
  save_models: true
  save_logs: true
  output_directory: "server_experiment_outputs"
  result_format: "json"
  
  files:
    - "experiment_results.json"
    - "performance_metrics.json"
    - "privacy_analysis.json"
    - "model_checkpoints/"
    - "logs/"

# 错误处理
error_handling:
  max_retries: 3
  retry_delay: 5
  enable_graceful_degradation: true
  timeout_seconds: 300
  
  fallback_strategies:
    gpu_unavailable: "cpu_mode"
    memory_insufficient: "reduce_batch_size"
    communication_failed: "local_processing"

# 扩展性测试
scaling_tests:
  client_scaling: [5, 10, 20, 50]
  data_scaling: [1000, 5000, 10000, 50000]
  gpu_scaling: [1, 2, 4, 8]
  
  performance_targets:
    throughput: 2000  # 样本/秒
    latency: 0.1      # 秒
    memory_usage: 16  # GB
    gpu_utilization: 0.8
