# -*- coding: utf-8 -*-
import numpy as np
import pandas as pd
import os
import json
import logging
from datetime import datetime
from sklearn.ensemble import IsolationForest, RandomForestClassifier
from sklearn.svm import OneClassSVM
from sklearn.neighbors import LocalOutlierFactor
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import roc_auc_score, f1_score
import warnings
warnings.filterwarnings('ignore')

logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

class SimpleAgent:
    """ç®€å•çš„æ™ºèƒ½ä½“"""
    
    def __init__(self, agent_id, agent_type, config=None):
        self.agent_id = agent_id
        self.agent_type = agent_type
        self.config = config or {}
        self.is_fitted = False
        self.model = None
        self.scaler = StandardScaler()
        
    def fit(self, X):
        """è®­ç»ƒæ™ºèƒ½ä½“"""
        try:
            X_scaled = self.scaler.fit_transform(X)
            
            if self.agent_type == "trend_analysis":
                self.model = IsolationForest(contamination=0.1, random_state=42)
            elif self.agent_type == "variance_analysis":
                self.model = OneClassSVM(nu=0.1, kernel='rbf')
            elif self.agent_type == "residual_analysis":
                self.model = LocalOutlierFactor(n_neighbors=20, contamination=0.1)
            elif self.agent_type == "statistical_analysis":
                self.model = IsolationForest(contamination=0.1, random_state=42)
            elif self.agent_type == "frequency_analysis":
                self.model = OneClassSVM(nu=0.1, kernel='linear')
            else:
                self.model = IsolationForest(contamination=0.1, random_state=42)
            
            self.model.fit(X_scaled)
            self.is_fitted = True
            logger.info("æ™ºèƒ½ä½“ %s è®­ç»ƒå®Œæˆ" % self.agent_id)
            
        except Exception as e:
            logger.error("æ™ºèƒ½ä½“ %s è®­ç»ƒå¤±è´¥: %s" % (self.agent_id, str(e)))
            self.is_fitted = False
    
    def predict(self, X):
        """é¢„æµ‹å¼‚å¸¸åˆ†æ•°"""
        if not self.is_fitted or self.model is None:
            logger.warning("æ™ºèƒ½ä½“ %s æœªè®­ç»ƒï¼Œè¿”å›éšæœºåˆ†æ•°" % self.agent_id)
            return np.random.rand(X.shape[0])
        
        try:
            X_scaled = self.scaler.transform(X)
            
            if hasattr(self.model, 'decision_function'):
                scores = self.model.decision_function(X_scaled)
            elif hasattr(self.model, 'score_samples'):
                scores = self.model.score_samples(X_scaled)
            else:
                scores = np.random.rand(X.shape[0])
            
            # å½’ä¸€åŒ–åˆ°0-1
            if len(scores) > 0:
                scores = (scores - scores.min()) / (scores.max() - scores.min() + 1e-8)
            else:
                scores = np.random.rand(X.shape[0])
            
            scores = np.clip(scores, 0.0, 1.0)
            return scores
            
        except Exception as e:
            logger.error("æ™ºèƒ½ä½“ %s é¢„æµ‹å¤±è´¥: %s" % (self.agent_id, str(e)))
            return np.random.rand(X.shape[0])

class SimpleMultiAgentDetector:
    """ç®€å•çš„å¤šæ™ºèƒ½ä½“æ£€æµ‹å™¨"""
    
    def __init__(self, agents, config=None):
        self.agents = {agent.agent_id: agent for agent in agents}
        self.config = config or {}
        self.is_fitted = False
        
        logger.info("åˆå§‹åŒ–å¤šæ™ºèƒ½ä½“æ£€æµ‹å™¨ï¼Œæ™ºèƒ½ä½“æ•°é‡: %d" % len(self.agents))
    
    def fit(self, X):
        """è®­ç»ƒæ‰€æœ‰æ™ºèƒ½ä½“"""
        logger.info("å¼€å§‹è®­ç»ƒå¤šæ™ºèƒ½ä½“æ£€æµ‹å™¨ï¼Œæ•°æ®å½¢çŠ¶: %s" % str(X.shape))
        
        for agent_id, agent in self.agents.items():
            try:
                agent.fit(X)
            except Exception as e:
                logger.error("æ™ºèƒ½ä½“ %s è®­ç»ƒå¤±è´¥: %s" % (agent_id, str(e)))
        
        self.is_fitted = True
        logger.info("å¤šæ™ºèƒ½ä½“æ£€æµ‹å™¨è®­ç»ƒå®Œæˆ")
    
    def predict(self, X):
        """å¤šæ™ºèƒ½ä½“åä½œé¢„æµ‹"""
        if not self.is_fitted:
            logger.warning("å¤šæ™ºèƒ½ä½“æ£€æµ‹å™¨æœªè®­ç»ƒï¼Œè¿”å›éšæœºåˆ†æ•°")
            return np.random.rand(X.shape[0])
        
        logger.info("å¼€å§‹å¤šæ™ºèƒ½ä½“åä½œé¢„æµ‹ï¼Œæ•°æ®å½¢çŠ¶: %s" % str(X.shape))
        
        agent_results = {}
        agent_scores = []
        
        for agent_id, agent in self.agents.items():
            try:
                scores = agent.predict(X)
                agent_results[agent_id] = {
                    'scores': scores,
                    'confidence': np.mean(scores),
                    'findings': "æ™ºèƒ½ä½“ %s æ£€æµ‹åˆ° %d ä¸ªæ½œåœ¨å¼‚å¸¸ç‚¹" % (agent_id, np.sum(scores > 0.5))
                }
                agent_scores.append(scores)
                logger.info("æ™ºèƒ½ä½“ %s é¢„æµ‹å®Œæˆï¼Œå¹³å‡åˆ†æ•°: %.4f" % (agent_id, np.mean(scores)))
            except Exception as e:
                logger.error("æ™ºèƒ½ä½“ %s é¢„æµ‹å¤±è´¥: %s" % (agent_id, str(e)))
                random_scores = np.random.rand(X.shape[0])
                agent_results[agent_id] = {
                    'scores': random_scores,
                    'confidence': 0.5,
                    'findings': "æ™ºèƒ½ä½“ %s é¢„æµ‹å¤±è´¥ï¼Œä½¿ç”¨éšæœºåˆ†æ•°" % agent_id
                }
                agent_scores.append(random_scores)
        
        if not agent_scores:
            logger.warning("æ²¡æœ‰æœ‰æ•ˆçš„æ™ºèƒ½ä½“é¢„æµ‹ç»“æœï¼Œè¿”å›éšæœºåˆ†æ•°")
            return np.random.rand(X.shape[0])
        
        # ä¼ ç»Ÿèåˆæ–¹æ³•ï¼šåŠ æƒå¹³å‡
        logger.info("ä½¿ç”¨åŠ æƒå¹³å‡è¿›è¡Œæ™ºèƒ½ä½“èåˆ...")
        
        stacked_scores = np.vstack(agent_scores).T
        
        confidences = [agent_results[aid]['confidence'] for aid in agent_results.keys()]
        weights = np.array(confidences)
        
        if np.sum(weights) > 0:
            weights = weights / np.sum(weights)
        else:
            weights = np.ones(len(confidences)) / len(confidences)
        
        final_scores = np.average(stacked_scores, axis=1, weights=weights)
        
        logger.info("èåˆå®Œæˆï¼Œæœ€ç»ˆåˆ†æ•°èŒƒå›´: [%.4f, %.4f]" % (np.min(final_scores), np.max(final_scores)))
        return final_scores

def create_simple_agents(config=None):
    """åˆ›å»ºç®€å•æ™ºèƒ½ä½“åˆ—è¡¨"""
    config = config or {}
    
    agents = [
        SimpleAgent("trend_agent", "trend_analysis", config),
        SimpleAgent("variance_agent", "variance_analysis", config),
        SimpleAgent("residual_agent", "residual_analysis", config),
        SimpleAgent("statistical_agent", "statistical_analysis", config),
        SimpleAgent("frequency_agent", "frequency_analysis", config)
    ]
    
    return agents

def load_dataset(dataset_name, data_base_path):
    """åŠ è½½æ•°æ®é›†"""
    try:
        if dataset_name == "MSL":
            train_path = os.path.join(data_base_path, "MSL/MSL_train.npy")
            test_path = os.path.join(data_base_path, "MSL/MSL_test.npy")
            test_label_path = os.path.join(data_base_path, "MSL/MSL_test_label.npy")
        elif dataset_name == "SMAP":
            train_path = os.path.join(data_base_path, "SMAP/SMAP_train.npy")
            test_path = os.path.join(data_base_path, "SMAP/SMAP_test.npy")
            test_label_path = os.path.join(data_base_path, "SMAP/SMAP_test_label.npy")
        elif dataset_name == "SMD":
            train_path = os.path.join(data_base_path, "SMD/SMD_train.npy")
            test_path = os.path.join(data_base_path, "SMD/SMD_test.npy")
            test_label_path = os.path.join(data_base_path, "SMD/SMD_test_labels.npy")
        elif dataset_name == "PSM":
            train_path = os.path.join(data_base_path, "PSM/PSM_train.npy")
            test_path = os.path.join(data_base_path, "PSM/PSM_test.npy")
            test_label_path = os.path.join(data_base_path, "PSM/PSM_test_labels.npy")
        elif dataset_name == "SWAT":
            train_path = os.path.join(data_base_path, "SWAT/SWAT_train.npy")
            test_path = os.path.join(data_base_path, "SWAT/SWAT_test.npy")
            test_label_path = os.path.join(data_base_path, "SWAT/SWAT_test_labels.npy")
        else:
            raise ValueError("æœªçŸ¥æ•°æ®é›†: %s" % dataset_name)
        
        train_data = np.load(train_path)
        test_data = np.load(test_path)
        test_labels = np.load(test_label_path)
        
        logger.info("%sæ•°æ®é›†å½¢çŠ¶: è®­ç»ƒ%s, æµ‹è¯•%s, æ ‡ç­¾%s" % (dataset_name, str(train_data.shape), str(test_data.shape), str(test_labels.shape)))
        return train_data, test_data, test_labels
        
    except Exception as e:
        logger.error("åŠ è½½%sæ•°æ®é›†å¤±è´¥: %s" % (dataset_name, str(e)))
        return None, None, None

def preprocess_data(train_data, test_data):
    """æ•°æ®é¢„å¤„ç†"""
    try:
        train_data = np.nan_to_num(train_data, nan=0.0)
        test_data = np.nan_to_num(test_data, nan=0.0)
        
        scaler = StandardScaler()
        train_data_scaled = scaler.fit_transform(train_data)
        test_data_scaled = scaler.transform(test_data)
        
        return train_data_scaled, test_data_scaled
        
    except Exception as e:
        logger.error("æ•°æ®é¢„å¤„ç†å¤±è´¥: %s" % str(e))
        return train_data, test_data

def run_baseline_methods(train_data, test_data, test_labels):
    """è¿è¡ŒåŸºå‡†æ–¹æ³•"""
    results = {}
    
    # IsolationForest
    try:
        logger.info("è¿è¡ŒIsolationForest...")
        model = IsolationForest(contamination=0.1, random_state=42)
        model.fit(train_data)
        scores = model.score_samples(test_data)
        scores = (scores - scores.min()) / (scores.max() - scores.min() + 1e-8)
        auroc = roc_auc_score(test_labels, scores)
        f1 = f1_score(test_labels, (scores > 0.5).astype(int))
        results['IsolationForest'] = {'auroc': auroc, 'f1': f1}
        logger.info("IsolationForest: AUROC %.4f, F1 %.4f" % (auroc, f1))
    except Exception as e:
        logger.warning("IsolationForestå¤±è´¥: %s" % str(e))
        results['IsolationForest'] = {'auroc': 0.5, 'f1': 0.0}
    
    # OneClassSVM
    try:
        logger.info("è¿è¡ŒOneClassSVM...")
        model = OneClassSVM(nu=0.1, kernel='rbf')
        model.fit(train_data)
        scores = model.decision_function(test_data)
        scores = (scores - scores.min()) / (scores.max() - scores.min() + 1e-8)
        auroc = roc_auc_score(test_labels, scores)
        f1 = f1_score(test_labels, (scores > 0.5).astype(int))
        results['OneClassSVM'] = {'auroc': auroc, 'f1': f1}
        logger.info("OneClassSVM: AUROC %.4f, F1 %.4f" % (auroc, f1))
    except Exception as e:
        logger.warning("OneClassSVMå¤±è´¥: %s" % str(e))
        results['OneClassSVM'] = {'auroc': 0.5, 'f1': 0.0}
    
    return results

def run_multi_agent_method(train_data, test_data, test_labels):
    """è¿è¡Œå¤šæ™ºèƒ½ä½“æ–¹æ³•"""
    try:
        logger.info("è¿è¡Œç®€å•å¤šæ™ºèƒ½ä½“æ–¹æ³•...")
        
        agents = create_simple_agents()
        detector = SimpleMultiAgentDetector(agents)
        
        detector.fit(train_data)
        scores = detector.predict(test_data)
        
        auroc = roc_auc_score(test_labels, scores)
        f1 = f1_score(test_labels, (scores > 0.5).astype(int))
        
        results = {"SimpleMultiAgent": {'auroc': auroc, 'f1': f1}}
        
        logger.info("SimpleMultiAgent: AUROC %.4f, F1 %.4f" % (auroc, f1))
        return results
        
    except Exception as e:
        logger.error("å¤šæ™ºèƒ½ä½“æ–¹æ³•å¤±è´¥: %s" % str(e))
        return {"SimpleMultiAgent": {'auroc': 0.5, 'f1': 0.0}}

def run_experiment(dataset_name, data_base_path):
    """è¿è¡Œå•ä¸ªæ•°æ®é›†å®éªŒ"""
    logger.info("ğŸš€ å¼€å§‹%sæ•°æ®é›†å®éªŒ" % dataset_name)
    logger.info("=" * 60)
    
    # åŠ è½½æ•°æ®
    train_data, test_data, test_labels = load_dataset(dataset_name, data_base_path)
    if train_data is None:
        return {}
    
    # æ•°æ®é¢„å¤„ç†
    train_data, test_data = preprocess_data(train_data, test_data)
    
    # è¿è¡ŒåŸºå‡†æ–¹æ³•
    logger.info("ğŸ” è¿è¡ŒåŸºå‡†æ–¹æ³•")
    baseline_results = run_baseline_methods(train_data, test_data, test_labels)
    
    # è¿è¡Œå¤šæ™ºèƒ½ä½“æ–¹æ³•
    logger.info("ğŸ¤– è¿è¡Œå¤šæ™ºèƒ½ä½“æ–¹æ³•")
    multi_agent_results = run_multi_agent_method(train_data, test_data, test_labels)
    
    # åˆå¹¶ç»“æœ
    all_results = baseline_results.copy()
    all_results.update(multi_agent_results)
    
    logger.info("âœ… %sæ•°æ®é›†å®éªŒå®Œæˆ" % dataset_name)
    return all_results

def main():
    """ä¸»å‡½æ•°"""
    data_base_path = "/home/jiangh/GinData/workspace/6.17cxz/data/jiangh@10.103.16.22"
    
    logger.info("ğŸš€ å¼€å§‹ç®€å•å¯å·¥ä½œçš„å¤šæ™ºèƒ½ä½“å¼‚å¸¸æ£€æµ‹å®éªŒ")
    logger.info("=" * 80)
    
    datasets = ["MSL", "SMAP", "SMD", "PSM", "SWAT"]
    all_results = {}
    
    for dataset in datasets:
        try:
            all_results[dataset] = run_experiment(dataset, data_base_path)
        except Exception as e:
            logger.error("%sæ•°æ®é›†å®éªŒå¤±è´¥: %s" % (dataset, str(e)))
            all_results[dataset] = {}
    
    # ä¿å­˜ç»“æœ
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    os.makedirs("outputs/simple_working_experiments", exist_ok=True)
    
    results_file = "outputs/simple_working_experiments/simple_results_%s.json" % timestamp
    with open(results_file, 'w', encoding='utf-8') as f:
        json.dump(all_results, f, indent=2, ensure_ascii=False)
    
    logger.info("ç»“æœå·²ä¿å­˜: %s" % results_file)
    logger.info("ğŸ‰ æ‰€æœ‰å®éªŒå®Œæˆï¼")

if __name__ == "__main__":
    main()
