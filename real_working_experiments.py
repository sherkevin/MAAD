# -*- coding: utf-8 -*-
import numpy as np
import pandas as pd
import os
import json
import logging
from datetime import datetime
from sklearn.ensemble import IsolationForest, RandomForestClassifier
from sklearn.svm import OneClassSVM
from sklearn.neighbors import LocalOutlierFactor
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import roc_auc_score, f1_score
import warnings
warnings.filterwarnings('ignore')

# å¯¼å…¥æˆ‘ä»¬çš„å·¥ä½œç‰ˆå¤šæ™ºèƒ½ä½“æ£€æµ‹å™¨
from src.agents.working_multi_agent_detector import WorkingMultiAgentDetector, create_working_agents

logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

class RealWorkingExperimentRunner:
    """çœŸæ­£å¯å·¥ä½œçš„å®éªŒè¿è¡Œå™¨"""
    
    def __init__(self, data_base_path: str, output_dir: str = "outputs/real_working_experiments"):
        self.data_base_path = data_base_path
        self.output_dir = output_dir
        self.results = {}
        
        # åˆ›å»ºè¾“å‡ºç›®å½•
        os.makedirs(output_dir, exist_ok=True)
        os.makedirs(f"{output_dir}/detailed_results", exist_ok=True)
    
    def load_dataset(self, dataset_name: str) -> tuple:
        """åŠ è½½æ•°æ®é›†"""
        try:
            if dataset_name == "MSL":
                train_path = os.path.join(self.data_base_path, "MSL/MSL_train.npy")
                test_path = os.path.join(self.data_base_path, "MSL/MSL_test.npy")
                test_label_path = os.path.join(self.data_base_path, "MSL/MSL_test_label.npy")
            elif dataset_name == "SMAP":
                train_path = os.path.join(self.data_base_path, "SMAP/SMAP_train.npy")
                test_path = os.path.join(self.data_base_path, "SMAP/SMAP_test.npy")
                test_label_path = os.path.join(self.data_base_path, "SMAP/SMAP_test_label.npy")
            elif dataset_name == "SMD":
                train_path = os.path.join(self.data_base_path, "SMD/SMD_train.npy")
                test_path = os.path.join(self.data_base_path, "SMD/SMD_test.npy")
                test_label_path = os.path.join(self.data_base_path, "SMD/SMD_test_labels.npy")
            elif dataset_name == "PSM":
                train_path = os.path.join(self.data_base_path, "PSM/PSM_train.npy")
                test_path = os.path.join(self.data_base_path, "PSM/PSM_test.npy")
                test_label_path = os.path.join(self.data_base_path, "PSM/PSM_test_labels.npy")
            elif dataset_name == "SWAT":
                train_path = os.path.join(self.data_base_path, "SWAT/SWAT_train.npy")
                test_path = os.path.join(self.data_base_path, "SWAT/SWAT_test.npy")
                test_label_path = os.path.join(self.data_base_path, "SWAT/SWAT_test_labels.npy")
            else:
                raise ValueError(f"æœªçŸ¥æ•°æ®é›†: {dataset_name}")
            
            # åŠ è½½æ•°æ®
            train_data = np.load(train_path)
            test_data = np.load(test_path)
            test_labels = np.load(test_label_path)
            
            logger.info(f"{dataset_name}æ•°æ®é›†å½¢çŠ¶: è®­ç»ƒ{train_data.shape}, æµ‹è¯•{test_data.shape}, æ ‡ç­¾{test_labels.shape}")
            return train_data, test_data, test_labels
            
        except Exception as e:
            logger.error(f"åŠ è½½{dataset_name}æ•°æ®é›†å¤±è´¥: {e}")
            return None, None, None
    
    def preprocess_data(self, train_data: np.ndarray, test_data: np.ndarray) -> tuple:
        """æ•°æ®é¢„å¤„ç†"""
        try:
            # å¤„ç†NaNå€¼
            train_data = np.nan_to_num(train_data, nan=0.0)
            test_data = np.nan_to_num(test_data, nan=0.0)
            
            # æ ‡å‡†åŒ–
            scaler = StandardScaler()
            train_data_scaled = scaler.fit_transform(train_data)
            test_data_scaled = scaler.transform(test_data)
            
            return train_data_scaled, test_data_scaled
            
        except Exception as e:
            logger.error(f"æ•°æ®é¢„å¤„ç†å¤±è´¥: {e}")
            return train_data, test_data
    
    def run_baseline_methods(self, train_data: np.ndarray, test_data: np.ndarray, test_labels: np.ndarray) -> dict:
        """è¿è¡ŒåŸºå‡†æ–¹æ³•"""
        results = {}
        
        # IsolationForest
        try:
            logger.info("è¿è¡ŒIsolationForest...")
            model = IsolationForest(contamination=0.1, random_state=42)
            model.fit(train_data)
            scores = model.score_samples(test_data)
            scores = (scores - scores.min()) / (scores.max() - scores.min() + 1e-8)
            auroc = roc_auc_score(test_labels, scores)
            f1 = f1_score(test_labels, (scores > 0.5).astype(int))
            results['IsolationForest'] = {'auroc': auroc, 'f1': f1}
            logger.info(f"IsolationForest: AUROC {auroc:.4f}, F1 {f1:.4f}")
        except Exception as e:
            logger.warning(f"IsolationForestå¤±è´¥: {e}")
            results['IsolationForest'] = {'auroc': 0.5, 'f1': 0.0}
        
        # OneClassSVM
        try:
            logger.info("è¿è¡ŒOneClassSVM...")
            model = OneClassSVM(nu=0.1, kernel='rbf')
            model.fit(train_data)
            scores = model.decision_function(test_data)
            scores = (scores - scores.min()) / (scores.max() - scores.min() + 1e-8)
            auroc = roc_auc_score(test_labels, scores)
            f1 = f1_score(test_labels, (scores > 0.5).astype(int))
            results['OneClassSVM'] = {'auroc': auroc, 'f1': f1}
            logger.info(f"OneClassSVM: AUROC {auroc:.4f}, F1 {f1:.4f}")
        except Exception as e:
            logger.warning(f"OneClassSVMå¤±è´¥: {e}")
            results['OneClassSVM'] = {'auroc': 0.5, 'f1': 0.0}
        
        # LocalOutlierFactor
        try:
            logger.info("è¿è¡ŒLocalOutlierFactor...")
            model = LocalOutlierFactor(n_neighbors=20, contamination=0.1)
            model.fit(train_data)
            scores = model.decision_function(test_data)
            scores = (scores - scores.min()) / (scores.max() - scores.min() + 1e-8)
            auroc = roc_auc_score(test_labels, scores)
            f1 = f1_score(test_labels, (scores > 0.5).astype(int))
            results['LocalOutlierFactor'] = {'auroc': auroc, 'f1': f1}
            logger.info(f"LocalOutlierFactor: AUROC {auroc:.4f}, F1 {f1:.4f}")
        except Exception as e:
            logger.warning(f"LocalOutlierFactorå¤±è´¥: {e}")
            results['LocalOutlierFactor'] = {'auroc': 0.5, 'f1': 0.0}
        
        # RandomForest (ä½œä¸ºç›‘ç£å­¦ä¹ çš„å¯¹æ¯”)
        try:
            logger.info("è¿è¡ŒRandomForest...")
            model = RandomForestClassifier(n_estimators=100, random_state=42)
            model.fit(train_data, np.zeros(train_data.shape[0]))  # ä½¿ç”¨æ­£å¸¸æ•°æ®è®­ç»ƒ
            scores = model.predict_proba(test_data)[:, 1]  # è·å–å¼‚å¸¸æ¦‚ç‡
            auroc = roc_auc_score(test_labels, scores)
            f1 = f1_score(test_labels, (scores > 0.5).astype(int))
            results['RandomForest'] = {'auroc': auroc, 'f1': f1}
            logger.info(f"RandomForest: AUROC {auroc:.4f}, F1 {f1:.4f}")
        except Exception as e:
            logger.warning(f"RandomForestå¤±è´¥: {e}")
            results['RandomForest'] = {'auroc': 0.5, 'f1': 0.0}
        
        return results
    
    def run_multi_agent_method(self, train_data: np.ndarray, test_data: np.ndarray, test_labels: np.ndarray, use_llm: bool = False) -> dict:
        """è¿è¡Œå¤šæ™ºèƒ½ä½“æ–¹æ³•"""
        try:
            logger.info("è¿è¡ŒçœŸæ­£å¯å·¥ä½œçš„å¤šæ™ºèƒ½ä½“æ–¹æ³•...")
            
            # åˆ›å»ºæ™ºèƒ½ä½“
            agents = create_working_agents()
            
            # åˆ›å»ºå¤šæ™ºèƒ½ä½“æ£€æµ‹å™¨
            config = {
                'use_llm_communication': use_llm,
                'aliyun_qwen_api_key': 'sk-dc7f3086d0564eb6ac282c7d66faea12' if use_llm else None
            }
            detector = WorkingMultiAgentDetector(agents, config)
            
            # è®­ç»ƒ
            detector.fit(train_data)
            
            # é¢„æµ‹
            scores = detector.predict(test_data)
            
            # è®¡ç®—æŒ‡æ ‡
            auroc = roc_auc_score(test_labels, scores)
            f1 = f1_score(test_labels, (scores > 0.5).astype(int))
            
            method_name = "WorkingMultiAgent" + ("_LLM" if use_llm else "")
            results = {method_name: {'auroc': auroc, 'f1': f1}}
            
            logger.info(f"{method_name}: AUROC {auroc:.4f}, F1 {f1:.4f}")
            return results
            
        except Exception as e:
            logger.error(f"å¤šæ™ºèƒ½ä½“æ–¹æ³•å¤±è´¥: {e}")
            return {"WorkingMultiAgent": {'auroc': 0.5, 'f1': 0.0}}
    
    def run_experiment(self, dataset_name: str) -> dict:
        """è¿è¡Œå•ä¸ªæ•°æ®é›†å®éªŒ"""
        logger.info(f"ğŸš€ å¼€å§‹{dataset_name}æ•°æ®é›†å®éªŒ")
        logger.info("=" * 60)
        
        # åŠ è½½æ•°æ®
        train_data, test_data, test_labels = self.load_dataset(dataset_name)
        if train_data is None:
            return {}
        
        # æ•°æ®é¢„å¤„ç†
        train_data, test_data = self.preprocess_data(train_data, test_data)
        
        # è¿è¡ŒåŸºå‡†æ–¹æ³•
        logger.info("ğŸ” è¿è¡ŒåŸºå‡†æ–¹æ³•")
        baseline_results = self.run_baseline_methods(train_data, test_data, test_labels)
        
        # è¿è¡Œå¤šæ™ºèƒ½ä½“æ–¹æ³•ï¼ˆä¸ä½¿ç”¨LLMï¼‰
        logger.info("ğŸ¤– è¿è¡Œå¤šæ™ºèƒ½ä½“æ–¹æ³•ï¼ˆä¼ ç»Ÿèåˆï¼‰")
        multi_agent_results = self.run_multi_agent_method(train_data, test_data, test_labels, use_llm=False)
        
        # è¿è¡Œå¤šæ™ºèƒ½ä½“æ–¹æ³•ï¼ˆä½¿ç”¨LLMï¼‰
        logger.info("ğŸ¤– è¿è¡Œå¤šæ™ºèƒ½ä½“æ–¹æ³•ï¼ˆLLMå¢å¼ºï¼‰")
        multi_agent_llm_results = self.run_multi_agent_method(train_data, test_data, test_labels, use_llm=True)
        
        # åˆå¹¶ç»“æœ
        all_results = {**baseline_results, **multi_agent_results, **multi_agent_llm_results}
        
        logger.info(f"âœ… {dataset_name}æ•°æ®é›†å®éªŒå®Œæˆ")
        return all_results
    
    def run_all_experiments(self):
        """è¿è¡Œæ‰€æœ‰å®éªŒ"""
        logger.info("ğŸš€ å¼€å§‹çœŸæ­£å¯å·¥ä½œçš„å¤šæ™ºèƒ½ä½“å¼‚å¸¸æ£€æµ‹å®éªŒ")
        logger.info("=" * 80)
        
        datasets = ["MSL", "SMAP", "SMD", "PSM", "SWAT"]
        
        for dataset in datasets:
            try:
                self.results[dataset] = self.run_experiment(dataset)
            except Exception as e:
                logger.error(f"{dataset}æ•°æ®é›†å®éªŒå¤±è´¥: {e}")
                self.results[dataset] = {}
        
        # ä¿å­˜ç»“æœ
        self.save_results()
        
        # ç”ŸæˆæŠ¥å‘Š
        self.generate_report()
        
        logger.info("ğŸ‰ æ‰€æœ‰å®éªŒå®Œæˆï¼")
    
    def save_results(self):
        """ä¿å­˜å®éªŒç»“æœ"""
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        
        # ä¿å­˜è¯¦ç»†ç»“æœ
        results_file = f"{self.output_dir}/real_working_results_{timestamp}.json"
        with open(results_file, 'w', encoding='utf-8') as f:
            json.dump(self.results, f, indent=2, ensure_ascii=False)
        
        # ä¿å­˜æ±‡æ€»ç»“æœ
        summary_data = []
        for dataset, methods in self.results.items():
            for method, metrics in methods.items():
                summary_data.append({
                    'dataset': dataset,
                    'method': method,
                    'auroc': metrics['auroc'],
                    'f1': metrics['f1']
                })
        
        summary_df = pd.DataFrame(summary_data)
        summary_file = f"{self.output_dir}/real_working_summary_{timestamp}.csv"
        summary_df.to_csv(summary_file, index=False)
        
        logger.info(f"ç»“æœå·²ä¿å­˜: {results_file}, {summary_file}")
    
    def generate_report(self):
        """ç”Ÿæˆå®éªŒæŠ¥å‘Š"""
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        report_file = f"{self.output_dir}/real_working_report_{timestamp}.md"
        
        with open(report_file, 'w', encoding='utf-8') as f:
            f.write("# çœŸæ­£å¯å·¥ä½œçš„å¤šæ™ºèƒ½ä½“å¼‚å¸¸æ£€æµ‹å®éªŒæŠ¥å‘Š\n\n")
            f.write(f"**å®éªŒæ—¥æœŸ**: {datetime.now().strftime('%Yå¹´%mæœˆ%dæ—¥')}\n")
            f.write(f"**å®éªŒç›®æ ‡**: éªŒè¯çœŸæ­£å¯å·¥ä½œçš„å¤šæ™ºèƒ½ä½“æ–¹æ³•æ€§èƒ½\n\n")
            
            f.write("## å®éªŒç»“æœæ‘˜è¦\n\n")
            
            for dataset, methods in self.results.items():
                f.write(f"### {dataset}æ•°æ®é›†\n")
                f.write("| æ–¹æ³• | AUROC | F1 |\n")
                f.write("|------|-------|----|\n")
                
                # æŒ‰AUROCæ’åº
                sorted_methods = sorted(methods.items(), key=lambda x: x[1]['auroc'], reverse=True)
                for method, metrics in sorted_methods:
                    f.write(f"| {method} | {metrics['auroc']:.4f} | {metrics['f1']:.4f} |\n")
                f.write("\n")
            
            # è®¡ç®—å¹³å‡æ€§èƒ½
            f.write("### å¹³å‡æ€§èƒ½å¯¹æ¯”\n")
            f.write("| æ–¹æ³• | å¹³å‡AUROC |\n")
            f.write("|------|----------|\n")
            
            method_avg_auroc = {}
            for dataset, methods in self.results.items():
                for method, metrics in methods.items():
                    if method not in method_avg_auroc:
                        method_avg_auroc[method] = []
                    method_avg_auroc[method].append(metrics['auroc'])
            
            for method, aurocs in method_avg_auroc.items():
                avg_auroc = np.mean(aurocs)
                f.write(f"| {method} | {avg_auroc:.4f} |\n")
        
        logger.info(f"å®éªŒæŠ¥å‘Šå·²ä¿å­˜: {report_file}")

def main():
    """ä¸»å‡½æ•°"""
    data_base_path = "/home/jiangh/GinData/workspace/6.17cxz/data/jiangh@10.103.16.22"
    
    runner = RealWorkingExperimentRunner(data_base_path)
    runner.run_all_experiments()

if __name__ == "__main__":
    main()
