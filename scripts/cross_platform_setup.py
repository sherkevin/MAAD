#!/usr/bin/env python3
"""
è·¨å¹³å°å…¼å®¹æ€§è®¾ç½®è„šæœ¬
å¤„ç†Macå’ŒLinuxä¹‹é—´çš„å·®å¼‚ï¼Œç¡®ä¿é¡¹ç›®åœ¨æœåŠ¡å™¨ä¸Šæ­£å¸¸è¿è¡Œ
"""

import os
import sys
import platform
import subprocess
import json
from pathlib import Path

def detect_platform():
    """æ£€æµ‹å½“å‰å¹³å°"""
    system = platform.system().lower()
    machine = platform.machine().lower()
    
    print(f"ğŸ” æ£€æµ‹å¹³å°ä¿¡æ¯:")
    print(f"   ç³»ç»Ÿ: {system}")
    print(f"   æ¶æ„: {machine}")
    print(f"   Pythonç‰ˆæœ¬: {sys.version}")
    
    if system == "darwin":
        return "mac"
    elif system == "linux":
        return "linux"
    elif system == "windows":
        return "windows"
    else:
        return "unknown"

def check_gpu_availability():
    """æ£€æŸ¥GPUå¯ç”¨æ€§"""
    try:
        import torch
        cuda_available = torch.cuda.is_available()
        print(f"ğŸ® GPUçŠ¶æ€: {'å¯ç”¨' if cuda_available else 'ä¸å¯ç”¨'}")
        
        if cuda_available:
            print(f"   CUDAç‰ˆæœ¬: {torch.version.cuda}")
            print(f"   GPUæ•°é‡: {torch.cuda.device_count()}")
            for i in range(torch.cuda.device_count()):
                print(f"   GPU {i}: {torch.cuda.get_device_name(i)}")
        
        return cuda_available
    except ImportError:
        print("âŒ PyTorchæœªå®‰è£…")
        return False

def create_platform_config():
    """åˆ›å»ºå¹³å°ç‰¹å®šé…ç½®"""
    platform_type = detect_platform()
    
    config = {
        "platform": platform_type,
        "gpu_available": check_gpu_availability(),
        "python_version": f"{sys.version_info.major}.{sys.version_info.minor}",
        "paths": {
            "project_root": str(Path.cwd()),
            "src_dir": "src",
            "config_dir": "configs",
            "output_dir": "outputs"
        }
    }
    
    # å¹³å°ç‰¹å®šè®¾ç½®
    if platform_type == "mac":
        config["device_preference"] = "cpu"  # Macé€šå¸¸ä½¿ç”¨CPU
        config["torch_backend"] = "mps" if check_gpu_availability() else "cpu"
        config["batch_size"] = 32  # Macå†…å­˜é™åˆ¶
    elif platform_type == "linux":
        config["device_preference"] = "cuda" if check_gpu_availability() else "cpu"
        config["torch_backend"] = "cuda" if check_gpu_availability() else "cpu"
        config["batch_size"] = 64  # LinuxæœåŠ¡å™¨é€šå¸¸æœ‰æ›´å¤šå†…å­˜
    else:
        config["device_preference"] = "cpu"
        config["torch_backend"] = "cpu"
        config["batch_size"] = 32
    
    return config

def create_requirements_file():
    """åˆ›å»ºrequirementsæ–‡ä»¶"""
    requirements = [
        "torch>=2.0.0",
        "torchvision>=0.15.0",
        "torchaudio>=2.0.0",
        "numpy<2.0",
        "scipy>=1.9.0",
        "scikit-learn>=1.1.0",
        "matplotlib>=3.5.0",
        "pandas>=1.4.0",
        "hydra-core>=1.2.0",
        "omegaconf>=2.2.0",
        "anomalib>=0.6.0",
        "statsmodels>=0.13.0",
        "python-dotenv>=0.19.0"
    ]
    
    # æ ¹æ®å¹³å°æ·»åŠ ç‰¹å®šä¾èµ–
    platform_type = detect_platform()
    if platform_type == "linux":
        requirements.extend([
            "nvidia-ml-py3>=7.352.0",  # GPUç›‘æ§
            "psutil>=5.9.0"  # ç³»ç»Ÿç›‘æ§
        ])
    
    return requirements

def create_server_script():
    """åˆ›å»ºæœåŠ¡å™¨è¿è¡Œè„šæœ¬"""
    script_content = '''#!/bin/bash
# æœåŠ¡å™¨è¿è¡Œè„šæœ¬
# è‡ªåŠ¨æ£€æµ‹ç¯å¢ƒå¹¶è¿è¡Œå®éªŒ

echo "ğŸš€ å¯åŠ¨å¤šæ™ºèƒ½ä½“ååŒå¼‚å¸¸æ£€æµ‹ç³»ç»Ÿ"
echo "=================================="

# æ£€æŸ¥Pythonç¯å¢ƒ
if ! command -v python3 &> /dev/null; then
    echo "âŒ Python3æœªå®‰è£…"
    exit 1
fi

# æ£€æŸ¥CUDAç¯å¢ƒ
if command -v nvidia-smi &> /dev/null; then
    echo "âœ… NVIDIAé©±åŠ¨å·²å®‰è£…"
    nvidia-smi --query-gpu=name,memory.total,memory.used --format=csv
else
    echo "âš ï¸  NVIDIAé©±åŠ¨æœªå®‰è£…ï¼Œå°†ä½¿ç”¨CPU"
fi

# æ¿€æ´»è™šæ‹Ÿç¯å¢ƒï¼ˆå¦‚æœå­˜åœ¨ï¼‰
if [ -d "venv" ]; then
    echo "ğŸ”§ æ¿€æ´»è™šæ‹Ÿç¯å¢ƒ"
    source venv/bin/activate
elif [ -d "conda_env" ]; then
    echo "ğŸ”§ æ¿€æ´»Condaç¯å¢ƒ"
    source conda_env/bin/activate
fi

# å®‰è£…ä¾èµ–
echo "ğŸ“¦ å®‰è£…ä¾èµ–åŒ…"
pip install -r requirements.txt

# è¿è¡Œç¯å¢ƒæ£€æŸ¥
echo "ğŸ” è¿è¡Œç¯å¢ƒæ£€æŸ¥"
python3 check_gpu_environment.py

# è¿è¡ŒGPUå…¼å®¹æ€§æµ‹è¯•
echo "ğŸ§ª è¿è¡ŒGPUå…¼å®¹æ€§æµ‹è¯•"
python3 test_gpu_compatibility.py

# è¿è¡Œå®Œæ•´æµ‹è¯•
echo "ğŸ§ª è¿è¡Œå®Œæ•´ç³»ç»Ÿæµ‹è¯•"
python3 test_integration_complete.py

# è¿è¡Œå®éªŒ
echo "ğŸš€ å¼€å§‹è¿è¡Œå®éªŒ"
python3 run_server_experiments.py --experiment all --gpu-test

echo "âœ… æ‰€æœ‰ä»»åŠ¡å®Œæˆ"
'''
    
    return script_content

def create_dockerfile():
    """åˆ›å»ºDockerfileç”¨äºå®¹å™¨åŒ–éƒ¨ç½²"""
    dockerfile_content = '''# å¤šæ™ºèƒ½ä½“ååŒå¼‚å¸¸æ£€æµ‹ç³»ç»Ÿ Dockerfile
FROM nvidia/cuda:11.8-devel-ubuntu20.04

# è®¾ç½®ç¯å¢ƒå˜é‡
ENV DEBIAN_FRONTEND=noninteractive
ENV PYTHONUNBUFFERED=1
ENV CUDA_VISIBLE_DEVICES=0

# å®‰è£…ç³»ç»Ÿä¾èµ–
RUN apt-get update && apt-get install -y \\
    python3 \\
    python3-pip \\
    python3-dev \\
    build-essential \\
    git \\
    wget \\
    curl \\
    && rm -rf /var/lib/apt/lists/*

# åˆ›å»ºé¡¹ç›®ç›®å½•
WORKDIR /app

# å¤åˆ¶é¡¹ç›®æ–‡ä»¶
COPY . .

# å®‰è£…Pythonä¾èµ–
RUN pip3 install --no-cache-dir -r requirements.txt

# è®¾ç½®æƒé™
RUN chmod +x run_server_experiments.py
RUN chmod +x check_gpu_environment.py

# æš´éœ²ç«¯å£ï¼ˆå¦‚æœéœ€è¦ï¼‰
EXPOSE 8000

# è¿è¡Œå‘½ä»¤
CMD ["python3", "run_server_experiments.py", "--experiment", "all"]
'''
    
    return dockerfile_content

def create_docker_compose():
    """åˆ›å»ºdocker-compose.yml"""
    compose_content = '''version: '3.8'

services:
  maaad-server:
    build: .
    container_name: maaad-server
    runtime: nvidia
    environment:
      - CUDA_VISIBLE_DEVICES=0
      - NVIDIA_VISIBLE_DEVICES=all
    volumes:
      - ./outputs:/app/outputs
      - ./configs:/app/configs
    ports:
      - "8000:8000"
    command: python3 run_server_experiments.py --experiment all
    restart: unless-stopped
'''
    
    return compose_content

def main():
    """ä¸»å‡½æ•°"""
    print("ğŸ”§ å¼€å§‹è·¨å¹³å°å…¼å®¹æ€§è®¾ç½®")
    print("=" * 50)
    
    # æ£€æµ‹å¹³å°
    platform_type = detect_platform()
    print(f"\nğŸ“Š å½“å‰å¹³å°: {platform_type}")
    
    # åˆ›å»ºé…ç½®
    config = create_platform_config()
    print(f"\nâš™ï¸  å¹³å°é…ç½®:")
    for key, value in config.items():
        print(f"   {key}: {value}")
    
    # ä¿å­˜é…ç½®
    with open('platform_config.json', 'w', encoding='utf-8') as f:
        json.dump(config, f, indent=2, ensure_ascii=False)
    print(f"\nğŸ’¾ å¹³å°é…ç½®å·²ä¿å­˜åˆ° platform_config.json")
    
    # åˆ›å»ºrequirementsæ–‡ä»¶
    requirements = create_requirements_file()
    with open('requirements.txt', 'w', encoding='utf-8') as f:
        f.write('\n'.join(requirements))
    print(f"ğŸ“¦ requirements.txt å·²åˆ›å»º")
    
    # åˆ›å»ºæœåŠ¡å™¨è„šæœ¬
    server_script = create_server_script()
    with open('run_server.sh', 'w', encoding='utf-8') as f:
        f.write(server_script)
    os.chmod('run_server.sh', 0o755)
    print(f"ğŸš€ æœåŠ¡å™¨è¿è¡Œè„šæœ¬å·²åˆ›å»º: run_server.sh")
    
    # åˆ›å»ºDockeræ–‡ä»¶
    dockerfile = create_dockerfile()
    with open('Dockerfile', 'w', encoding='utf-8') as f:
        f.write(dockerfile)
    print(f"ğŸ³ Dockerfile å·²åˆ›å»º")
    
    compose_file = create_docker_compose()
    with open('docker-compose.yml', 'w', encoding='utf-8') as f:
        f.write(compose_file)
    print(f"ğŸ³ docker-compose.yml å·²åˆ›å»º")
    
    # åˆ›å»ºé¡¹ç›®åŒæ­¥è„šæœ¬
    sync_script = f'''#!/bin/bash
# é¡¹ç›®åŒæ­¥è„šæœ¬
# ä»æœ¬åœ°MacåŒæ­¥åˆ°LinuxæœåŠ¡å™¨

echo "ğŸ”„ å¼€å§‹åŒæ­¥é¡¹ç›®åˆ°æœåŠ¡å™¨"
echo "========================="

# è®¾ç½®æœåŠ¡å™¨ä¿¡æ¯
SERVER_USER="your_username"
SERVER_HOST="your_server_ip"
SERVER_PATH="/path/to/project"

# åŒæ­¥é¡¹ç›®æ–‡ä»¶
echo "ğŸ“ åŒæ­¥é¡¹ç›®æ–‡ä»¶..."
rsync -avz --exclude='__pycache__' --exclude='*.pyc' --exclude='.git' \\
    ./ {SERVER_USER}@{SERVER_HOST}:{SERVER_PATH}/

# åŒæ­¥å®Œæˆååœ¨æœåŠ¡å™¨ä¸Šè¿è¡Œ
echo "ğŸš€ åœ¨æœåŠ¡å™¨ä¸Šè¿è¡Œé¡¹ç›®..."
ssh {SERVER_USER}@{SERVER_HOST} "cd {SERVER_PATH} && chmod +x run_server.sh && ./run_server.sh"

echo "âœ… åŒæ­¥å®Œæˆ"
'''
    
    with open('sync_to_server.sh', 'w', encoding='utf-8') as f:
        f.write(sync_script)
    os.chmod('sync_to_server.sh', 0o755)
    print(f"ğŸ”„ æœåŠ¡å™¨åŒæ­¥è„šæœ¬å·²åˆ›å»º: sync_to_server.sh")
    
    print(f"\nğŸ‰ è·¨å¹³å°å…¼å®¹æ€§è®¾ç½®å®Œæˆï¼")
    print(f"ğŸ“‹ ä¸‹ä¸€æ­¥:")
    print(f"   1. ç¼–è¾‘ sync_to_server.sh è®¾ç½®æœåŠ¡å™¨ä¿¡æ¯")
    print(f"   2. è¿è¡Œ ./sync_to_server.sh åŒæ­¥åˆ°æœåŠ¡å™¨")
    print(f"   3. åœ¨æœåŠ¡å™¨ä¸Šè¿è¡Œ ./run_server.sh")
    
    return True

if __name__ == "__main__":
    success = main()
    sys.exit(0 if success else 1)
